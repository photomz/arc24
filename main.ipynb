{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"},{"sourceId":8615222,"sourceType":"datasetVersion","datasetId":5156304},{"sourceId":9594533,"sourceType":"datasetVersion","datasetId":5852456},{"sourceId":9852521,"sourceType":"datasetVersion","datasetId":5527180},{"sourceId":200567623,"sourceType":"kernelVersion"},{"sourceId":62292,"sourceType":"modelInstanceVersion","modelInstanceId":52023,"modelId":71342},{"sourceId":62308,"sourceType":"modelInstanceVersion","modelInstanceId":52038,"modelId":71342},{"sourceId":103906,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":104529,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":107047,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":107048,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":107078,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":107717,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":107718,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":108410,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":108825,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":109428,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":109987,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":111077,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":111313,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":112633,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":113178,"sourceType":"modelInstanceVersion","modelInstanceId":77352,"modelId":98761},{"sourceId":121302,"sourceType":"modelInstanceVersion","modelInstanceId":102059,"modelId":126273},{"sourceId":121304,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":121368,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":121561,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":122911,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":122912,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":123108,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":124484,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":124485,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":125288,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":129666,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":129836,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":133466,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":151755,"sourceType":"modelInstanceVersion","modelInstanceId":128859,"modelId":98761},{"sourceId":151756,"sourceType":"modelInstanceVersion","modelInstanceId":128860,"modelId":122699},{"sourceId":152332,"sourceType":"modelInstanceVersion","modelInstanceId":129376,"modelId":122699},{"sourceId":152336,"sourceType":"modelInstanceVersion","modelInstanceId":129379,"modelId":98761},{"sourceId":153533,"sourceType":"modelInstanceVersion","modelInstanceId":128859,"modelId":98761},{"sourceId":154938,"sourceType":"modelInstanceVersion","modelInstanceId":128859,"modelId":98761},{"sourceId":154939,"sourceType":"modelInstanceVersion","modelInstanceId":128859,"modelId":98761},{"sourceId":154947,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":158099,"sourceType":"modelInstanceVersion","modelInstanceId":134359,"modelId":126273},{"sourceId":158111,"sourceType":"modelInstanceVersion","modelInstanceId":134371,"modelId":126273},{"sourceId":158905,"sourceType":"modelInstanceVersion","modelInstanceId":134377,"modelId":98761},{"sourceId":159133,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":159757,"sourceType":"modelInstanceVersion","modelInstanceId":134377,"modelId":98761},{"sourceId":160210,"sourceType":"modelInstanceVersion","modelInstanceId":102061,"modelId":98761},{"sourceId":160608,"sourceType":"modelInstanceVersion","modelInstanceId":134377,"modelId":98761},{"sourceId":160674,"sourceType":"modelInstanceVersion","modelInstanceId":134383,"modelId":98761}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Single-task Test-time fine-tuning for ARC24","metadata":{}},{"cell_type":"markdown","source":"## Goal","metadata":{}},{"cell_type":"markdown","source":"In this notebook I will explore a version of test-time fine-tuning that adapts the base model for each task.\n\nInstead of fine-tuning in all the test tasks together, I will fine-tune a model for each of the tasks. Hopefully this will bring the improvement that Jack Cole is talking about in the MLST podcast.","metadata":{}},{"cell_type":"markdown","source":"## Configuration and imports","metadata":{}},{"cell_type":"code","source":"!jq 'to_entries | .[:3] | from_entries' /kaggle/input/arc24-source-code/new_partitions/val_rs7.json > smaller_val_challenges.json","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:13.217543Z","iopub.execute_input":"2024-11-09T08:22:13.21798Z","iopub.status.idle":"2024-11-09T08:22:14.371642Z","shell.execute_reply.started":"2024-11-09T08:22:13.217943Z","shell.execute_reply":"2024-11-09T08:22:14.370238Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#qwen25-0.5b/18 step320_bs1 8e-5lr_lin x96 ENS\nclass cfg:\n    # Model\n    model_path = '/kaggle/input/qwen2.5/transformers/0.5b-instruct/1'\n    input_lora_path = '/kaggle/input/loras/transformers/qwen2.5-0.5b-instruct/18'\n    finetune_prompt_version = 'output-from-examples-v1'\n    inference_prompt_version = 'output-from-examples-v1'\n    merged_model_path = '/kaggle/tmp/qwen_merged_model'\n    grid_encoder = 'GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))' #GridCodeBlockEncoder(MinimalGridEncoder())\n    max_model_len = 10240\n    # Dataset\n    dataset_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n    #dataset_path = '/kaggle/input/arc24-source-code/new_partitions/val_rs7.json'\n    #dataset_path = 'smaller_val_challenges.json'\n    split_size = 1 # How many tasks there would be on each split, use 1 for the canonical single-task test-time fine-tuning\n    # Fine-tuning params\n    max_steps = 320\n    learning_rate = 8e-5 #1e-4 for lora smaller than 512\n    lr_scheduler_type: str = \"linear\" #linear, constant_with_warmup, cosine, cosine_with_restarts\n    batch_size = 1\n    max_seq_len = 5120 #3456, 5120, (I believe 5120 might be causing problems with lora 128)\n    # Inference params\n    predictions_per_task = 96 # multiple of 8\n    inference_timeout = \"12m\" # max inference time per split, I estimate that for 128 preds Qwen-0.5B takes 6 min in the worst case (50 splits)\n    # Ensemble\n    ensemble_with_2020: bool = True\n\nimport os\nis_dry_run = cfg.dataset_path == '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json' and not os.getenv('KAGGLE_IS_COMPETITION_RERUN')\nif is_dry_run:\n    print('This is a dry run, no inference nor installation of packages will be done')\n    \nassert os.path.exists(cfg.model_path)\nassert os.path.exists(cfg.input_lora_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:14.374498Z","iopub.execute_input":"2024-11-09T08:22:14.374893Z","iopub.status.idle":"2024-11-09T08:22:14.389919Z","shell.execute_reply.started":"2024-11-09T08:22:14.374813Z","shell.execute_reply":"2024-11-09T08:22:14.387307Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import logging\nimport subprocess\nimport sys\nimport json\nimport glob\nimport os\nimport shutil\nfrom tqdm.auto import tqdm\n\nif not is_dry_run:\n    sys.path.append('/kaggle/input/arc24-source-code')\n    os.environ['PYTHONPATH'] += ':/kaggle/input/omniarc-source-code'\n\n# Configure logging to output to the notebook console\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:14.404238Z","iopub.execute_input":"2024-11-09T08:22:14.404629Z","iopub.status.idle":"2024-11-09T08:22:14.50087Z","shell.execute_reply.started":"2024-11-09T08:22:14.404587Z","shell.execute_reply":"2024-11-09T08:22:14.499791Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 0. Launch 2020 solution in the background","metadata":{}},{"cell_type":"code","source":"if not is_dry_run and cfg.ensemble_with_2020:\n    print('Launching 2020 solution in the background')\n    args = [\n        #'taskset', '-c', '0', apparently this will restrict the job to a single cpu\n        'python',\n        '/kaggle/input/arc24-source-code/full_2020_solution.py',\n        f'--dataset_filepath={cfg.dataset_path}',\n        '--icecuber_output_filepath=icecuber_submission.json',\n        '--dsl_output_filepath=submission_program_search.json']\n    full_2020_solution_process = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:14.50329Z","iopub.execute_input":"2024-11-09T08:22:14.503585Z","iopub.status.idle":"2024-11-09T08:22:14.509539Z","shell.execute_reply.started":"2024-11-09T08:22:14.503559Z","shell.execute_reply":"2024-11-09T08:22:14.508634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Install libraries and launch resource monitor","metadata":{}},{"cell_type":"code","source":"%%time\nif not is_dry_run:\n    !bash /kaggle/input/arc24-source-code/install_libraries.sh","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:14.510607Z","iopub.execute_input":"2024-11-09T08:22:14.510938Z","iopub.status.idle":"2024-11-09T08:22:19.187031Z","shell.execute_reply.started":"2024-11-09T08:22:14.510903Z","shell.execute_reply":"2024-11-09T08:22:19.185738Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not is_dry_run:\n    from arc24.utils import ResourceMonitor\n    monitor = ResourceMonitor(interval=1)\n    monitor.start()","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:19.188994Z","iopub.execute_input":"2024-11-09T08:22:19.18944Z","iopub.status.idle":"2024-11-09T08:22:19.285233Z","shell.execute_reply.started":"2024-11-09T08:22:19.189396Z","shell.execute_reply":"2024-11-09T08:22:19.284206Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Prepare data for training","metadata":{}},{"cell_type":"code","source":"if not is_dry_run:\n    single_task_datasets_path = 'single_task_datasets'\n    os.makedirs(single_task_datasets_path, exist_ok=True)\n    with open(cfg.dataset_path, 'r') as f:\n        items = list(json.load(f).items())\n    \n    assert len(items) % cfg.split_size == 0\n    \n    for batch_idx in tqdm(range(len(items)//cfg.split_size), desc='Creating single task datasets'):\n        data = dict(items[batch_idx*cfg.split_size: (batch_idx + 1)*cfg.split_size])\n        assert len(data) == cfg.split_size\n        task_id = list(data.keys())[0]\n        with open(os.path.join(single_task_datasets_path, f'{task_id}.json'), 'w') as f:\n            json.dump(data, f)\n    ! ls -lh {single_task_datasets_path}","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:19.286521Z","iopub.execute_input":"2024-11-09T08:22:19.286945Z","iopub.status.idle":"2024-11-09T08:22:20.586296Z","shell.execute_reply.started":"2024-11-09T08:22:19.286903Z","shell.execute_reply":"2024-11-09T08:22:20.585282Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not is_dry_run:\n    training_datasets_path = 'single_task_training_datasets'\n    os.makedirs(training_datasets_path, exist_ok=True)\n    dataset_filepaths = glob.glob(os.path.join(single_task_datasets_path, '*.json'))\n    for dataset_filepath in tqdm(dataset_filepaths, desc='Creating ttft training datasets'):\n        !python /kaggle/input/arc24-source-code/create_n-1_dataset.py \\\n        {dataset_filepath} \\\n        {os.path.join(training_datasets_path, os.path.basename(dataset_filepath))}","metadata":{"execution":{"iopub.status.busy":"2024-11-09T08:22:20.587659Z","iopub.execute_input":"2024-11-09T08:22:20.588007Z","iopub.status.idle":"2024-11-09T08:22:21.931667Z","shell.execute_reply.started":"2024-11-09T08:22:20.587975Z","shell.execute_reply":"2024-11-09T08:22:21.930666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Test-time fine-tuning","metadata":{}},{"cell_type":"code","source":"%%time\ndef clean_train_output_except_adapter(output_dir):\n    \"\"\"\n    Max Disk is 57.6GiB, but around 8GiB are already used. \n    If each checkpoint weights 265M, that would be 26GB for 100 savings. The optimizer was using just 133M.\n    However on '/kaggle/working/' we can only save 20GB, the run that had the disk error used 50 splits, each split was using around 400M, so it makes sense\n    \"\"\"\n    #!rm -rf {output_dir}/runs\n    !rm {output_dir}/*/*.pth {output_dir}/*/*.pt {output_dir}/*/*.md {output_dir}/*/*.txt {output_dir}/*/*.bin {output_dir}/*/token*\n    !rm {output_dir}/*/added_tokens.json {output_dir}/*/special_tokens_map.json {output_dir}/*/vocab.json {output_dir}/*/trainer_state.json\n    \nif not is_dry_run:\n    dataset_filepaths = glob.glob(os.path.join(training_datasets_path, '*.json'))\n    dataset_filepaths = sorted(dataset_filepaths, key=lambda x: os.path.getsize(x)) # starting by the smaller files might be safer if there are memory problems\n    checkpoints_folder = '/kaggle/tmp/checkpoints' # https://www.kaggle.com/docs/notebooks#technical-specifications\n    os.makedirs(checkpoints_folder, exist_ok=True)\n    for dataset_filepath in tqdm(dataset_filepaths, desc='Finetuning models'):\n        output_dir = os.path.join(checkpoints_folder, os.path.splitext(os.path.basename(dataset_filepath))[0])\n        !python /kaggle/input/arc24-source-code/fine-tuning.py \\\n        --model_path={cfg.model_path} \\\n        --adapter_path={cfg.input_lora_path} \\\n        --output_dir={output_dir} \\\n        --train_datasets {dataset_filepath} {cfg.finetune_prompt_version} \\\n        --val_dataset {dataset_filepath} {cfg.finetune_prompt_version} \\\n        --max_steps={cfg.max_steps} \\\n        --eval_steps={cfg.max_steps*2} \\\n        --max_seq_len={cfg.max_seq_len} \\\n        --learning_rate={cfg.learning_rate} \\\n        --lr_scheduler_type={cfg.lr_scheduler_type} \\\n        --batch_size={cfg.batch_size} \\\n        --report_to=tensorboard \\\n        --grid_encoder=\"{cfg.grid_encoder}\" \\\n        --remove_train_samples_to_fit_max_seq_len \\\n        --torch_dtype=float16 \\\n        --warmup_ratio 0.1 \\\n        --no-verbose\n        clean_train_output_except_adapter(output_dir)\n        logging.info(f'Finished fine-tuning for split {dataset_filepaths.index(dataset_filepath) + 1}/{len(dataset_filepaths)}')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-09T08:22:21.933342Z","iopub.execute_input":"2024-11-09T08:22:21.933684Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh {checkpoints_folder}/*/checkpoint*/adapter_model.safetensors","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Inference","metadata":{}},{"cell_type":"code","source":"%%time\nif is_dry_run:\n    with open('submission.json', 'w') as f:\n        json.dump(dict(dry_run=True), f)\nelse:\n    inference_path = 'inference'\n    os.makedirs(inference_path)\n    os.environ['VLLM_LOGGING_LEVEL'] = 'ERROR'\n    dataset_filepaths = sorted(glob.glob(os.path.join(single_task_datasets_path, '*.json')))\n    for dataset_filepath in tqdm(dataset_filepaths):\n        task_id = os.path.splitext(os.path.basename(dataset_filepath))[0]\n        checkpoint_path = os.path.join(checkpoints_folder, task_id, f'checkpoint-{cfg.max_steps}')\n        if not os.path.exists(checkpoint_path):\n            print(f'Checkpoint path does not exist: {checkpoint_path}')\n            checkpoint_path = cfg.input_lora_path\n        \n        !python /kaggle/input/arc24-source-code/merge_lora.py \\\n        --base_model_path={cfg.model_path} \\\n        --lora_path={checkpoint_path} \\\n        --output_path={cfg.merged_model_path}\n        \n        output_filepath = os.path.join(inference_path, f'{task_id}_inference.json')\n        while not os.path.exists(output_filepath):\n            ! timeout {cfg.inference_timeout} python /kaggle/input/arc24-source-code/inference.py\\\n            --model_path={cfg.merged_model_path} \\\n            --prompt_version={cfg.inference_prompt_version} \\\n            --dataset={dataset_filepath} \\\n            --output_filepath={output_filepath} \\\n            --max_model_len={cfg.max_model_len} \\\n            --grid_encoder=\"{cfg.grid_encoder}\" \\\n            --swap_space 0 \\\n            --predictions_per_task={cfg.predictions_per_task}  \n            if not os.path.exists(output_filepath):\n                print('\\t\\tWARNING, INFERENCE DID TIMEOUT!')\n                \n        logging.info(f'Finished inference for split {dataset_filepaths.index(dataset_filepath) + 1}/{len(dataset_filepaths)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# combine all the predictions into single files\nif not is_dry_run:\n    filepaths = glob.glob(os.path.join(inference_path, '*_inference.json'))\n    solutions = dict()\n    for filepath in tqdm(filepaths):\n        with open(filepath, 'r') as f:\n            solutions.update(json.load(f))\n    with open('submission_all.json', 'w') as f:\n        json.dump(solutions, f)\n\n    filepaths = glob.glob(os.path.join(inference_path, '*_task_results.json'))\n    task_results = []\n    for filepath in tqdm(filepaths):\n        with open(filepath, 'r') as f:\n            task_results.extend(json.load(f))\n    with open('submission_all_task_results.json', 'w') as f:\n        json.dump(task_results, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not is_dry_run:\n    !python /kaggle/input/arc24-source-code/voting.py \\\n    --input_filepath=submission_all_task_results.json \\\n    --output_filepath=submission_voting.json  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not is_dry_run and cfg.dataset_path != '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json':\n    sys.path.append('/kaggle/input/arc24-source-code')\n    from evaluation import (\n        load_arc_data_with_solutions, evaluate,\n        study_effect_of_the_number_of_solutions,\n        study_attempt_accuracy,\n        visualize_tasks_and_predictions)\n    \n    print('Results with all the predictions')\n    with open('submission_all.json', 'r') as f:\n        solutions = json.load(f)\n    data = load_arc_data_with_solutions(cfg.dataset_path)\n    evaluate(data, solutions)\n    \n    study_effect_of_the_number_of_solutions(solutions, data)\n    visualize_tasks_and_predictions(solutions, data, only_correct=True)\n    \n    print('Results from selected 2 attemps')\n    with open('submission_voting.json', 'r') as f:\n        solutions = json.load(f)\n    evaluate(data, solutions)\n    study_attempt_accuracy(solutions, data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Program search \n\nhttps://www.kaggle.com/code/mehrankazeminia/3-arc24-developed-2020-winning-solutions\n","metadata":{}},{"cell_type":"code","source":"if not is_dry_run and cfg.ensemble_with_2020:\n    # old code to call program search dsl sequentially\n    #!python /kaggle/input/arc24-source-code/program_search_dsl.py \\\n    #--dataset_filepath={cfg.dataset_path} \\\n    #--output_filepath=submission_program_search.json\n    \n    print('Waiting for icecuber process to end')\n    full_2020_solution_process.wait()\n    stdout, stderr = full_2020_solution_process.communicate()\n    print(\"Script output:\", stdout.decode())\n    print(\"Script errors:\", stderr.decode())\n    \n    #old code to call icecuber solution sequentially\n    #!python /kaggle/input/arc24-source-code/icecuber_solution.py \\\n    #--dataset_filepath={cfg.dataset_path} \\\n    #--output_filepath=icecuber_submission.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Combine solutions","metadata":{}},{"cell_type":"code","source":"if not is_dry_run:\n    if cfg.ensemble_with_2020:\n        !python /kaggle/input/arc24-source-code/combine_submissions.py \\\n        --sub_1=submission_program_search.json \\\n        --sub_2=icecuber_submission.json \\\n        --output=submission_2020.json \\\n        --give_preference_to_second_submission_on_second_attempt\n\n        !python /kaggle/input/arc24-source-code/combine_submissions.py \\\n        --sub_1=submission_2020.json \\\n        --sub_2=submission_voting.json \\\n        --output=submission.json \\\n        --give_preference_to_second_submission_on_second_attempt\n    else:\n        !cp submission_voting.json submission.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not is_dry_run and cfg.dataset_path != '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json':\n    print('Results from final submission')\n    with open('submission.json', 'r') as f:\n        solutions = json.load(f)\n    evaluate(data, solutions)\n    study_attempt_accuracy(solutions, data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Clean","metadata":{}},{"cell_type":"code","source":"def clean():\n    import glob\n    import os\n    import shutil\n    for filepath in glob.glob('*'):\n        if filepath == 'submission.json':\n            continue\n        if os.path.isdir(filepath):\n            shutil.rmtree(filepath)\n        else:\n            os.remove(filepath)\n    !rm -rf /kaggle/tmp/*\n\nclean()\n!ls -lh","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Show resources usage","metadata":{}},{"cell_type":"code","source":"if not is_dry_run:\n    monitor.stop()\n    monitor.plot()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## References","metadata":{}},{"cell_type":"markdown","source":"- https://www.kaggle.com/code/ironbar/fine-tuned-llms-for-arc24-challenge\n- https://www.kaggle.com/code/ironbar/fine-tune-llm-on-arc\n- https://www.kaggle.com/code/mehrankazeminia/3-arc24-developed-2020-winning-solutions","metadata":{}},{"cell_type":"markdown","source":"## TODO","metadata":{}},{"cell_type":"markdown","source":"- [x] Can I log metrics when not using wandb? Yes, simply by setting the log to tensorboard\n- [x] Combine with icecuber solution\n- [x] Group imports\n- [ ] Assert that the solution has all the predictions, if there is a timeout there might be missing predictions. It seems that VLLM can get stuck sometimes.","metadata":{}}]}